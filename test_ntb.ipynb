{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids_path = 'data/train_phobert_extraction_ids_no_negative.txt'\n",
    "dev_ids_path =  'data/test_phobert_extraction_ids_no_negative.txt'\n",
    "log_file = 'logs/reader_logs/phobert_no_negative.log'\n",
    "model_dir = 'checkpoint/phobert_extraction_model_no_negative'\n",
    "pretrained_model_name = 'phobert'\n",
    "pretrained_model_path = 'vinai/phobert-base'\n",
    "maxlen = 256\n",
    "batch_size = 32\n",
    "\n",
    "device='cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances = open(train_ids_path, \"r\",\n",
    "                       encoding=\"utf-8\").read().splitlines()\n",
    "dev_instances = open(dev_ids_path, \"r\", encoding=\"utf-8\").read().splitlines()\n",
    "# dev_instances = [i for i in dev_instances if '217, 2921, 42, 1340, 2326, 1529, 76,' in i]\n",
    "# dev_instances = [dev_instances[1411]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from models.extraction_model import BertForQuestionAnswering, RobertaForQuestionAnswering, Trainer\n",
    "from transformers import BertTokenizer, PhobertTokenizer\n",
    "\n",
    "tokenizer = PhobertTokenizer.from_pretrained(\n",
    "    pretrained_model_path, do_lower_case=False, remove_accents=False)\n",
    "model = RobertaForQuestionAnswering.from_pretrained('checkpoint/phobert_extraction_model/epoch_4', num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_helper.custom_dataset import CustomDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = CustomDataset(\n",
    "    train_instances, maxlen=maxlen, pad_token_id=tokenizer.pad_token_id)\n",
    "dev_dataset = CustomDataset(\n",
    "    dev_instances, maxlen=maxlen, pad_token_id=tokenizer.pad_token_id)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(pretrained_model=model, tokenizer=tokenizer, device=device,log_file='test_eval.log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2210it [00:37, 59.16it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(dev_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"correct_question_extraction_eval.txt\") as f:\n",
    "    correct_indices = [int(i) for i in f.read().strip().split(\"\\n\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"correct_questions.txt\") as f:\n",
    "    correct_qa_questions = f.read().strip().split('\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5959276018099547"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_indices)/len(dev_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6159509202453988"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_indices)/len(correct_qa_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer\n",
    "correct_qa_questions = [ViTokenizer.tokenize(i).replace(\"_\",' ') for i in correct_qa_questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.read_csv(\"data/test_phobert_extraction.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.question = test_df.question.map(lambda x: x.replace('_',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_df = test_df[~(test_df.question).isin(correct_qa_questions)]\n",
    "wrong_df = wrong_df[wrong_df.index.isin(correct_indices)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngoài việc tạo khí ôxy , khí quyển còn có chức năng gì ?\n",
      "Sinh_quyển của Trái_Đất tạo ra các thay_đổi khá lớn đối_với bầu khí_quyển và , ngược_lại , cũng nhờ có bầu khí_quyển mà có những bước phát_triển đáng_kể . Sự quang_hợp sinh ôxy tiến_triển từ 2,7 tỷ năm trước đã tạo ra bầu_không_khí chứa nitơ - ôxy tồn_tại như ngày_nay . Sự thay_đổi này tạo điều_kiện thuận_lợi cho sự phổ_biến của các vi_sinh_vật hiếu_khí , cũng như việc tầng ôzôn - cùng với từ_trường của Trái_Đất - đã ngăn_chặn các tia phóng_xạ , cho_phép sự sống tồn_tại trên Trái_Đất . Các chức_năng khác của khí_quyển đối_với sự sống bao_gồm vận_chuyển , cung_cấp các loại khí hữu_dụng , đốt cháy các thiên_thạch nhỏ trước khi chúng va_chạm với mặt_đất và điều_hoà_nhiệt_độ . Hiện_tượng cuối_cùng được biết dưới cái tên_hiệu ứng nhà_kính : các phân_tử khí thu nhiệt_năng toả ra từ mặt_đất , làm tăng nhiệt_độ trung_bình . Điôxít cacbon , hơi_nước , mêtan và ôzôn là các khí nhà_kính đầu_tiên trong bầu khí_quyển của Trái_Đất . Nếu không có hiệu_ứng duy_trì nhiệt này , nhiệt_độ trung_bình bề_mặt sẽ là - 18 ° C và sự sống sẽ không có khả_năng tồn_tại .\n",
      "['Các chức_năng khác của khí_quyển đối_với sự sống bao_gồm vận_chuyển , cung_cấp các loại khí hữu_dụng , đốt cháy các thiên_thạch nhỏ trước khi chúng va_chạm với mặt_đất và điều_hoà_nhiệt_độ', 'vận_chuyển , cung_cấp các loại khí hữu_dụng , đốt cháy các thiên_thạch nhỏ trước khi chúng va_chạm với mặt_đất và điều_hoà_nhiệt_độ', 'vận_chuyển , cung_cấp các loại khí hữu_dụng , đốt cháy các thiên_thạch nhỏ trước khi chúng va_chạm với mặt_đất và điều_hoà_nhiệt_độ', 'vận_chuyển , cung_cấp các loại khí hữu_dụng , đốt cháy các thiên_thạch nhỏ trước khi chúng va_chạm với mặt_đất và điều_hoà_nhiệt_độ']\n"
     ]
    }
   ],
   "source": [
    "sample = wrong_df.sample(1)\n",
    "print(sample.question.values[0])\n",
    "print(sample.context.values[0])\n",
    "print(sample.answer.values[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>start_char_position</th>\n",
       "      <th>start_token_position</th>\n",
       "      <th>end_token_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>Điều gì sẽ xảy ra nếu Edward có thể giành lại ...</td>\n",
       "      <td>Isabella và Mortimer nhanh_chóng trả_thù chế_đ...</td>\n",
       "      <td>['nhiều thành_viên chính_phủ mới có_thể bị đe_...</td>\n",
       "      <td>[471, 466, 466, 466]</td>\n",
       "      <td>[94, 94, 94, 94]</td>\n",
       "      <td>[100, 109, 100, 100]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "1335  Điều gì sẽ xảy ra nếu Edward có thể giành lại ...   \n",
       "\n",
       "                                                context  \\\n",
       "1335  Isabella và Mortimer nhanh_chóng trả_thù chế_đ...   \n",
       "\n",
       "                                                 answer   start_char_position  \\\n",
       "1335  ['nhiều thành_viên chính_phủ mới có_thể bị đe_...  [471, 466, 466, 466]   \n",
       "\n",
       "     start_token_position    end_token_position  \n",
       "1335     [94, 94, 94, 94]  [100, 109, 100, 100]  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2210"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2208, 6)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'([0, 19978, 10893, 7, 24912, 11, 320, 25, 602, 114, 2, 24912, 10, 16, 25966, 9969, 4, 1263, 1270, 794, 63, 444, 16353, 5, 251, 25, 17643, 35913, 4, 25966, 10, 82, 7250, 11023, 4, 3966, 292, 845, 6, 346, 43238, 4, 81, 15, 21, 292, 239, 239, 4, 51, 4, 91, 110, 2463, 15, 6970, 4, 25966, 44, 8238, 28, 43220, 6, 8143, 7430, 11561, 9472, 12, 1959, 130, 229, 40, 110, 2463, 23, 5, 1008, 147, 25966, 8, 59331, 11494, 7, 24912, 4, 2504, 11, 1224, 302, 22, 7250, 11023, 22, 6, 22, 7519, 845, 22, 65, 1250, 59331, 11494, 7, 24912, 411, 63, 150, 2055, 4, 33, 29, 3214, 1120, 8, 137, 1366, 52092, 4, 646, 9, 11007, 4, 17129, 4, 6914, 6, 9341, 1330, 5, 10928, 59331, 11494, 7, 1692, 8, 553, 9, 2127, 22535, 49095, 4, 6, 1836, 32, 5592, 2093, 238, 7279, 6, 8246, 5, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [76, 76, 76, 76], [78, 78, 78, 78])'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_instances[1411]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nước Đức hiện nay sự hợp thành của hai nước nào trong thời kỳ Đồng minh chiếm đóng Đức ?'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.question.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_ids =[0, 19978, 10893, 7, 24912, 11, 320, 25, 602, 114, 2, 24912, 10, 16, 25966, 9969, 4, 1263, 1270, 794, 63, 444, 16353, 5, 251, 25, 17643, 35913, 4, 25966, 10, 82, 7250, 11023, 4, 3966, 292, 845, 6, 346, 43238, 4, 81, 15, 21, 292, 239, 239, 4, 51, 4, 91, 110, 2463, 15, 6970, 4, 25966, 44, 8238, 28, 43220, 6, 8143, 7430, 11561, 9472, 12, 1959, 130, 229, 40, 110, 2463, 23, 5, 1008, 147, 25966, 8, 59331, 11494, 7, 24912, 4, 2504, 11, 1224, 302, 22, 7250, 11023, 22, 6, 22, 7519, 845, 22, 65, 1250, 59331, 11494, 7, 24912, 411, 63, 150, 2055, 4, 33, 29, 3214, 1120, 8, 137, 1366, 52092, 4, 646, 9, 11007, 4, 17129, 4, 6914, 6, 9341, 1330, 5, 10928, 59331, 11494, 7, 1692, 8, 553, 9, 2127, 22535, 49095, 4, 6, 1836, 32, 5592, 2093, 238, 7279, 6, 8246, 5, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'Tu',\n",
       " 'thất',\n",
       " 'của',\n",
       " 'Edward',\n",
       " 'được',\n",
       " 'đặt',\n",
       " 'ở',\n",
       " 'đâu',\n",
       " '?',\n",
       " '</s>',\n",
       " 'Edward',\n",
       " 'có',\n",
       " 'một',\n",
       " 'hoàng_cung',\n",
       " 'lưu_động',\n",
       " ',',\n",
       " 'di_chuyển',\n",
       " 'khắp',\n",
       " 'đất_nước',\n",
       " 'theo',\n",
       " 'chân',\n",
       " 'Nhà_vua',\n",
       " '.',\n",
       " 'Khi',\n",
       " 'ở',\n",
       " 'Cung_điện',\n",
       " 'Westminster',\n",
       " ',',\n",
       " 'hoàng_cung',\n",
       " 'có',\n",
       " 'hai',\n",
       " 'đại_@@',\n",
       " 'sảnh',\n",
       " ',',\n",
       " 'bảy',\n",
       " 'phòng',\n",
       " 'ngủ',\n",
       " 'và',\n",
       " 'ba',\n",
       " 'nhà_nguyện',\n",
       " ',',\n",
       " 'cùng',\n",
       " 'với',\n",
       " 'những',\n",
       " 'phòng',\n",
       " 'nhỏ',\n",
       " 'nhỏ',\n",
       " ',',\n",
       " 'nhưng',\n",
       " ',',\n",
       " 'do',\n",
       " 'cuộc',\n",
       " 'xung_đột',\n",
       " 'với',\n",
       " 'Scotland',\n",
       " ',',\n",
       " 'hoàng_cung',\n",
       " 'lại',\n",
       " 'dời',\n",
       " 'về',\n",
       " 'Yorkshire',\n",
       " 'và',\n",
       " 'Nor@@',\n",
       " 'thu@@',\n",
       " 'mb@@',\n",
       " 'ria',\n",
       " 'trong',\n",
       " 'phần_lớn',\n",
       " 'thời_gian',\n",
       " 'diễn',\n",
       " 'ra',\n",
       " 'cuộc',\n",
       " 'xung_đột',\n",
       " 'này',\n",
       " '.',\n",
       " 'Chính',\n",
       " 'giữa',\n",
       " 'hoàng_cung',\n",
       " 'là',\n",
       " 'tư_th@@',\n",
       " 'ất',\n",
       " 'của',\n",
       " 'Edward',\n",
       " ',',\n",
       " 'lần_lượt',\n",
       " 'được',\n",
       " 'chia',\n",
       " 'thành',\n",
       " '\"',\n",
       " 'đại_@@',\n",
       " 'sảnh',\n",
       " '\"',\n",
       " 'và',\n",
       " '\"',\n",
       " 'buồng',\n",
       " 'ngủ',\n",
       " '\"',\n",
       " ';',\n",
       " 'quy_mô',\n",
       " 'tư_th@@',\n",
       " 'ất',\n",
       " 'của',\n",
       " 'Edward',\n",
       " 'thay_đổi',\n",
       " 'theo',\n",
       " 'từng',\n",
       " 'thời_kỳ',\n",
       " ',',\n",
       " 'vào',\n",
       " 'năm',\n",
       " '13@@',\n",
       " '17',\n",
       " 'là',\n",
       " 'khoảng',\n",
       " '500',\n",
       " 'strong',\n",
       " ',',\n",
       " 'bao_gồm',\n",
       " 'các',\n",
       " 'hiệp_sĩ',\n",
       " ',',\n",
       " 'cận_vệ',\n",
       " ',',\n",
       " 'đầu_bếp',\n",
       " 'và',\n",
       " 'phu',\n",
       " 'vận_chuyển',\n",
       " '.',\n",
       " 'Xung_quanh',\n",
       " 'tư_th@@',\n",
       " 'ất',\n",
       " 'của',\n",
       " 'vua',\n",
       " 'là',\n",
       " 'đông',\n",
       " 'các',\n",
       " 'tr@@',\n",
       " 'iề@@',\n",
       " 'u_thần',\n",
       " ',',\n",
       " 'và',\n",
       " 'dường_như',\n",
       " 'cũng',\n",
       " 'cuốn_hút',\n",
       " 'thành_phần',\n",
       " 'gái',\n",
       " 'bán_dâm',\n",
       " 'và',\n",
       " 'phạm_nhân',\n",
       " '.',\n",
       " '</s>']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = input_ids[0:]\n",
    "word_pieces = tokenizer.convert_ids_to_tokens(pred,skip_special_tokens=False)\n",
    "word_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('làm việc dạy chỉ tổng quát , những bài viết ở đấy được viết và quản lý bởi người riêng',\n",
       "  74,\n",
       "  90,\n",
       "  1.4787357)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from predictor import ReaderPredictor\n",
    "# reader = ReaderPredictor()\n",
    "context ='Vài dự án bách khoa toàn thư đã và đang hoạt động. Vài dự án có quy định cộng tác và sở hữu bài viết theo kiểu truyền thống, ví dụ như Bách khoa toàn thư Triết học Stanford bởi những nhà chuyên môn hoặc dự án Nupedia đã đóng cửa. Những website thoải mái hơn như là h2g2 và Everything2 làm việc dạy chỉ tổng quát, những bài viết ở đấy được viết và quản lý bởi người riêng. Những dự án như là Wikipedia, Susning.nu và Enciclopedia Libre là wiki, trong đó các bài viết được phát triển bởi nhiều tác giả, và không có quá trình kiểm duyệt bài viết chính thức. Trong những bách khoa toàn thư wiki đó, Wikipedia được trở thành bách khoa lớn nhất tính theo số bài viết và số chữ. Khác với nhiều bách khoa toàn thư, nó cho phép sử dụng nội dung dưới Giấy phép Văn bản Tự do GNU.'\n",
    "question = 'Những website như h2g2 và Everything2 được dùng để làm gì?'\n",
    "reader.predict(question, context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([90])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_ids.cpu().numpy().tolist()[0]==input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<s>'],\n",
       " ['Những'],\n",
       " ['website'],\n",
       " ['như'],\n",
       " ['h', '2', 'g', '2'],\n",
       " ['và'],\n",
       " ['Ever', 'yth', 'ing', '2'],\n",
       " ['được'],\n",
       " ['dùng'],\n",
       " ['để'],\n",
       " ['làm'],\n",
       " ['gì'],\n",
       " ['?'],\n",
       " ['</s>'],\n",
       " ['Vài'],\n",
       " ['dự_án'],\n",
       " ['bách_', 'khoa_toàn_thư'],\n",
       " ['đã'],\n",
       " ['và'],\n",
       " ['đang'],\n",
       " ['hoạt_động'],\n",
       " ['.'],\n",
       " ['Vài'],\n",
       " ['dự_án'],\n",
       " ['có'],\n",
       " ['quy_định'],\n",
       " ['cộng_tác'],\n",
       " ['và'],\n",
       " ['sở_hữu'],\n",
       " ['bài'],\n",
       " ['viết'],\n",
       " ['theo'],\n",
       " ['kiểu'],\n",
       " ['truyền_thống'],\n",
       " [','],\n",
       " ['ví_dụ'],\n",
       " ['như'],\n",
       " ['Bách_', 'khoa_toàn_thư'],\n",
       " ['Triết_học'],\n",
       " ['Stanford'],\n",
       " ['bởi'],\n",
       " ['những'],\n",
       " ['nhà'],\n",
       " ['chuyên_môn'],\n",
       " ['hoặc'],\n",
       " ['dự_án'],\n",
       " ['Nu', 'pedia'],\n",
       " ['đã'],\n",
       " ['đóng_cửa'],\n",
       " ['.'],\n",
       " ['Những'],\n",
       " ['website'],\n",
       " ['thoải_mái'],\n",
       " ['hơn'],\n",
       " ['như'],\n",
       " ['là'],\n",
       " ['h', '2', 'g', '2'],\n",
       " ['và'],\n",
       " ['Ever', 'yth', 'ing', '2'],\n",
       " ['làm_việc'],\n",
       " ['dạy'],\n",
       " ['chỉ'],\n",
       " ['tổng_quát'],\n",
       " [','],\n",
       " ['những'],\n",
       " ['bài'],\n",
       " ['viết'],\n",
       " ['ở'],\n",
       " ['đấy'],\n",
       " ['được'],\n",
       " ['viết'],\n",
       " ['và'],\n",
       " ['quản_lý'],\n",
       " ['bởi'],\n",
       " ['người'],\n",
       " ['riêng'],\n",
       " ['.'],\n",
       " ['Những'],\n",
       " ['dự_án'],\n",
       " ['như'],\n",
       " ['là'],\n",
       " ['Wikipedia'],\n",
       " [','],\n",
       " ['Sus', 'ning'],\n",
       " ['.'],\n",
       " ['nu'],\n",
       " ['và'],\n",
       " ['En', 'c', 'ic', 'lo', 'pe', 'dia_', 'Lib', 're'],\n",
       " ['là'],\n",
       " ['w', 'iki'],\n",
       " [','],\n",
       " ['trong'],\n",
       " ['đó'],\n",
       " ['các'],\n",
       " ['bài'],\n",
       " ['viết'],\n",
       " ['được'],\n",
       " ['phát_triển'],\n",
       " ['bởi'],\n",
       " ['nhiều'],\n",
       " ['tác_giả'],\n",
       " [','],\n",
       " ['và'],\n",
       " ['không'],\n",
       " ['có'],\n",
       " ['quá_trình'],\n",
       " ['kiểm_duyệt'],\n",
       " ['bài'],\n",
       " ['viết'],\n",
       " ['chính_thức'],\n",
       " ['.'],\n",
       " ['Trong'],\n",
       " ['những'],\n",
       " ['bách_', 'khoa_toàn_thư'],\n",
       " ['w', 'iki'],\n",
       " ['đó'],\n",
       " [','],\n",
       " ['Wikipedia'],\n",
       " ['được'],\n",
       " ['trở_thành'],\n",
       " ['bách_', 'khoa'],\n",
       " ['lớn'],\n",
       " ['nhất'],\n",
       " ['tính'],\n",
       " ['theo'],\n",
       " ['số'],\n",
       " ['bài'],\n",
       " ['viết'],\n",
       " ['và'],\n",
       " ['số'],\n",
       " ['chữ'],\n",
       " ['.'],\n",
       " ['Khác'],\n",
       " ['với'],\n",
       " ['nhiều'],\n",
       " ['bách_', 'khoa_toàn_thư'],\n",
       " [','],\n",
       " ['nó'],\n",
       " ['cho_phép'],\n",
       " ['sử_dụng'],\n",
       " ['nội_dung'],\n",
       " ['dưới'],\n",
       " ['Giấy_phép'],\n",
       " ['Văn_bản'],\n",
       " ['Tự_do'],\n",
       " ['G', 'N', 'U.'],\n",
       " ['</s>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>'],\n",
       " ['<pad>']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Những website như h2g2 và Everything2 được dùng để làm gì ?,\"Vài dự_án bách_khoa_toàn_thư đã và đang hoạt_động . Vài dự_án có quy_định cộng_tác và sở_hữu bài viết theo kiểu truyền_thống , ví_dụ như Bách_khoa_toàn_thư Triết_học Stanford bởi những nhà chuyên_môn hoặc dự_án Nupedia đã đóng_cửa . Những website thoải_mái hơn như là h2g2 và Everything2 làm_việc dạy chỉ tổng_quát , những bài viết ở đấy được viết và quản_lý bởi người riêng . Những dự_án như là Wikipedia , Susning . nu và Enciclopedia_Libre là wiki , trong đó các bài viết được phát_triển bởi nhiều tác_giả , và không có quá_trình kiểm_duyệt bài viết chính_thức . Trong những bách_khoa_toàn_thư wiki đó , Wikipedia được trở_thành bách_khoa lớn nhất tính theo số bài viết và số chữ . Khác với nhiều bách_khoa_toàn_thư , nó cho_phép sử_dụng nội_dung dưới Giấy_phép Văn_bản Tự_do GNU .\",làm_việc dạy chỉ tổng_quát,288,45,48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f0cd17c6fec694e464f77e135f2de1532ecd08f538120620b8d919555fed4f6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
